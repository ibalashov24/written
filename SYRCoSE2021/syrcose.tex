\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage[switch]{lineno}
\usepackage{stmaryrd}
\usepackage{float}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{tabularx,booktabs}


\begin{document}
\linenumbers
\title{Linear Algebra Partial Evaluation Using AnyDSL*\\
{\footnotesize \textsuperscript{*}Note: NOT FINAL}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Ilya Balashov}
\IEEEauthorblockA{\textit{Saint Petersburg State University} \\
7/9 Universitetskaya nab., \\ St. Petersburg, 199034 Russia \\
i.balashov@2017.spbu.ru}
\and
\IEEEauthorblockN{Semyon Grigorev}
\IEEEauthorblockA{\textit{Saint Petersburg State University} \\
7/9 Universitetskaya nab., \\ St. Petersburg, 199034 Russia \\
s.v.grigoriev@spbu.ru
}
\and
\IEEEauthorblockN{Daniil Berezun}
\IEEEauthorblockA{\textit{Saint Petersburg State University} \\
7/9 Universitetskaya nab., \\ St. Petersburg, 199034 Russia \\
\textcolor{red}{SPBU email!}}
}
\maketitle

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}
Recent years have seen a significant increase in sizes and complexity of programs in different areas of software engineering. A possible way of satisfying these requirements is usage of automatic optimization tools and techniques, operating with program sources.

For instance, so-called \textit{partial evaluation} (or specialization) \cite{jones1993partial} technique is being actively used over last years as a way to optimize program execution time automatically, using known statically data. A special tool named \textit{partial evaluator} (or specializer) analyzes data (for example, function parameters) which was provided ahead of evaluation time and applies several program optimization techniques based on the structure of this data. 

One of the possible applications of partial evaluation is optimization of algorithms expressed in terms of linear algebra. It is well-known \cite{kepner2011graph} that many graph algorithms could be constructed using the language of some basic operations: matrix multiplication, Kronecker (tensor) product etc. Moreover, it is possible to use matrices as a data storage in algorithms from different other area. If it is possible to build an algorithm (or representation of it's data) using some relatively small algorithmic bricks, therefore, it should be possible to utilize small and statically known bricks for optimization purposes using partial evaluation technique.

Existing results in the area of applied usage of partial evaluation for automatic linear algebra algorithms or algorithms with matrix data optimization are limited by several partially successful experiments with CUDA- and Clang-based partial evaluators \cite{tyurin2020optimizing} \textcolor{red}{[my coursework???]}. The main contribution of this work  will be providing some experiments on linear algebra partial evaluation with AnyDSL \cite{leissa2018anydsl} framework on CPU. We will show that partial evaluation using this specific partial evaluator gives significant increase in execution times for all tested algorithms on the most of given datasets.


\section{Background}

\subsection{Partial evaluation}

Let's suppose:

\begin{itemize}
	\item $P$ is a program, which takes values $a_n\ [n=1..m]$ as an input
	\item $mix$ is a program which is defined as $mix\ [P, a_1] = P_a$
	\item $\llbracket P \rrbracket [a_1, a_2, .., a_m] = \llbracket P_a \rrbracket [a_2, .., a_m]$
\end{itemize}
Then the transformation of $P$ and $a_1$ to $P_a$ using $mix$ is called \textit{partial evaluation} \cite{jones1993partial}. Program $mix$ is called \textit{partial evaluator}. In other words, partial evaluation is a technique for evaluating parts of the program ahead of compilation with the usage of static input data.

Despite partial evaluation is initially being used by Ershov \cite{ershov1982mixed}, Jones \cite{jones1993partial} and other scientist in their work for compiler generation via Futamura projections \cite{futamura1983partial}, it could also be used for program optimization. For instance, partial evaluator can employ static data to unfold loops and conditional operators, propagate constants, etc \cite{jones1993partial}. 

% Difficulties of PE
However partial evaluation is a powerful method of program optimization, it is inherent in several difficulties. Firstly, partial evaluator could inflate source code size heavily because of transformation such as loop unfolding and static data substitution. Therefore, evaluation results (code structure, bottlenecks, etc.) \textcolor{red}{formal} assessment becomes a non-trivial problem very often. To solve issue in some degree, modern tools like AnyDSL \cite{leissa2018anydsl} tends to translate evaluated code into some intermediate representation which is often much easier to understand and analyze. Secondly, divergent program partial evaluation with the application of average-quality tool may lead to the evaluation process divergence \cite{jones1993partial}. So, the programmer have to be very careful while using this technique for optimization purposes. Finally, partial evaluation imposes serious requirements on the programmer qualification: deep understanding of evaluation process is highly required. To solve this issue modern tools are introducing simplified language constructions, such as a special partial evaluation wrappers \cite{leissa2018anydsl}, attribute-driven evaluation \cite{10.1007/978-3-319-74313-4_27} and many other various and creative methods.

\subsection{Graph algorithms in the linear algebra language}

It is widely known that many of graph algorithms could be explained in the language of matrices \cite{kepner2011graph,davis2019algorithm}. Linear algebra allows constructing algorithms like Breadth-First Search or Shortest Path Search with exploitation of basic linear algebra operations: matrix multiplication, Kronecker product, etc. 

For instance, one may write down Breadth-First Search in the manner of (listing). Each iteration of the algorithm represents one matrix-vector multiplication.
\bigskip

\colorbox{red}{Formula/Code Listing}
\bigskip

Therefore, if it was possible to speed up different matrix multiplication algorithms, it would be possible to speed up a large class of algorithms. 

One of the possible basic sets of linear algebra algorithms and operations for graph algorithm construction is named \textit{GraphBLAS} standard \cite{davis2019algorithm,moreira2018implementing}. However SuiteSparse GraphBLAS is usually considered as the state-of-art implementation of this standard \cite{davis2019algorithm}, there are a number of custom wrappers and implementations \cite{pygraphblas, ibmgraphblas}.

\section{Algorithms implementation}

All algorithms were implemented using AnyDSL Impala domain-specific language \cite{leissa2018anydsl} for partial evaluation. AnyDSL framework was chosen due to it's Impala DSL with comparatively simple Rust-like syntax and relatively available documentation. Algorithm code is represented as computation kernels, which is further linked with Google Benchmark-based \cite{gbenchmark} benchmarking code. Each algorithm was implemented in Impala twice: with partial evaluation language constructions and without them (therefore, with no partial evaluation).

Also, every algorithm was implemented with an alternative tool or framework that is usually used in practice for algorithm implementation in the corresponding area. In details, the following programs were used:
\begin{itemize}
	\item SuiteSparse GraphBLAS(link) --- for graph algorithms in the terms of linear algebra
	\item Grep and eGrep --- for algorithms on strings and regular expressions
\end{itemize}


All the code is placed on GitHub:
\begin{center}
\href{https://github.com/ibalashov24/spec\_experiments}{https://github.com/ibalashov24/spec\_experiments}
\end{center}

\section{Experimental design}

In this section we will describe our experimental design for partial evaluation of selected algorithms using AnyDSL framework.

\subsection{Experimental setup}

Configuration of the experimental stand was:
\begin{itemize}
	\item Intel Core i5-7440HQ (4x3.8GHz) CPU
	\item 16Gb RAM
	\item Ubuntu 20.04
\end{itemize}

Tools' versions were fixed on the following commits from their official repositories:
\begin{itemize}
	\item Google Benchmark \cite{gbenchmark} --- commit dated 22 December 2020
	\item AnyDSL \cite{leissa2018anydsl} --- commit dated 8 December 2020
	\item SuiteSparse GraphBLAS \colorbox{red}{\cite{moreira2018implementing}} --- commit dated 14 July 2020
\end{itemize}

Default (e)Grep from Ubuntu 20.04 was employed.

We used Harwell-Boeing matrix collection \cite{duff1992users} (a subset of it is also known as SuiteSparse matrix collection \cite{davis2011university}) because it contains reasonably diverse set of matrices. COO (COOrdinate list) sparse matrix format was used.

For string algorithms, we used random strings and traffic dumps as sources and and random strings or latin words as patterns. Regular expressions (finite automata) were converted to COO sparse representation with our modification of Re2dfa tool \cite{re2dfa}.

AnyDSL partial evaluation tool was executed in JIT-mode \colorbox{red}{\cite{leissa2018anydsl}}, which allows to perform partial evaluation at the run time.



\subsection{Research questions}

To evaluate our approach, we design experiments to address the following research questions:

\begin{itemize}
	\item[\textbf{Q1:}] Does partial evaluated benefits string and matrix-based graph algorithms performance (execution time) comparing to their basic versions?
	\item[\textbf{Q2:}] In which degree partially evaluated algorithms code performance gets closer to their state-of-art implementations?
	\item[\textbf{Q3:}] \textcolor{blue}{How does partial evaluator influences algorithms' code size?}
\end{itemize}

\subsection{Result metrics}
To evaluate the performance of partially evaluated code, we adopt the following widely used metrics for application performance:
\begin{itemize}
	\item \textbf{Execution time} is computed by Google Benchmark tool and measured in nanoseconds. For each of algorithm the tool gives three numbers: time spent in real life, time spent on CPU and iteration number. We took \textit{time spent in real life} in order to consider all hardware delays (for example, memory access delays).
	
	The smaller execution time is better.
	
	\item \textbf{Measure error} is computed by Google Benchmark tool and measured in percents. 
	
	Numbers smaller than $0.01\%$ are considered as good result which guarantees relatively small threat to validity.
	
	\item \textcolor{blue}{\textbf{Code ramification} metric consists of the number of lines of code in LLVM IR representation of algorithms generated by AnyDSL and the number of conditional jumps in this representation.	
	The smaller code ramification is better.}
\end{itemize}

\section{Results}
This section presents our experimental results by addressing the research questions.

\subsection{Does partial evaluation with AnyDSL benefits string and matrix-based graph algorithms performance comparing to their basic versions?}

\begin{table}[]
	\begin{tabular}{lllll}
		Time, ns.   & bcsstk16 x 2blocks & bcsstk16 x eye3 & fs1831 x 2blocks & fs1831 x eye3 \\
		\multicolumn{5}{c}{Matrix-Matrix product}                                             \\
		No spec     & 3569461            & 152191          & 48082            & 7526          \\
		Spec        & 172553             & 94126           & 20487            & 8025          \\
		SuiteSparse & 5302               & 1825            & 1825             & 2056          \\
		\multicolumn{5}{c}{Kronecker product}                                                 \\
		No spec     & 186                & 126550          & 22509            & 966           \\
		Spec        & 34.5               & 157196          & 2016             & 893           \\
		SuiteSparse & 198                & 199             & 197              & 199          
	\end{tabular}
\end{table}

For matrix algorithms (both matrix-matrix product and Kronecker product), 4 matrices were taken from Harwell-Boeing: \textit{bcsstk16}, \textit{fs1831}, \textit{2blocks} and \textit{eye3}. As seen from [table 1], partial evaluation gives significant, more than several times, speed up on test cases involving \textit{2blocks} as right \textcolor{red}{multiplicator}. It may be explained with relatively distributed structure of \textit{2blocks} matrix non-zero elements, that allows partial evaluator to effectively perform optimizations like loop unfolding and constant propagation.\\
In contrast, non-zero elements of \textit{eye3} matrix are concentrated near the main diagonal of the matrix, that leads to relatively small execution time benefit of partial evaluation --- loop unfolding does not discard any empty iterations.

For string algorithms, we may observe much more noticeable execution time increase after partial evaluation than in graph algorithms. As could be seen from [table 2], the speed up lays between 10 and 100 times depending on the test. The reason of such a significant increase is that the most of iterations in classic substring search and pattern matching algorithms \cite{cormen2009introduction} with matrix input are not empty, like in previously discussed algorithms on sparse matrices graphs. Also, in substring search algorithm evaluation is simplified by the fact that the data is being iterated successively.\\
Moreover, there is absent of non-logical operations with both source and pattern data as operands in these algorithms, so the partial evaluator is able to apply constant propagation optimization heavily due to trivial data separation.

The results show that in general partial evaluation with AnyDSL benefits string and matrix-based graph algorithms execution time comparing to their basic versions.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{../../LinearAlgebraImpala/MatrixMultiplication/Charts/jit_drawer/prod_suitesp}
	\caption{Execution time of matrix multiplication algorithm comparison between SuiteSparse and partially evaluated code using AnyDSL}
\end{figure}

\begin{figure}
	\centering
\end{figure}

\subsection{In which degree partially evaluated algorithms code performance gets closer to their state-of-art implementations?}

[Tables 3 and 4] show the time (in nanoseconds) of execution of matrix-based graph and string algorithms respectively. 

For the string algorithms, we can see that partially evaluated code outperforms Grep (for pattern matching) and eGrep (for regular expressions matching) in several times (2 to 10000) on each of datasets. However AnyDSL beat (e)Grep in both pattern and regular expression matching problems, we could see that the latter gave by several orders of magnitude stronger results. According to our analysis, it could be the result of using COO representation for regular expression's transition graph in the experiment: linear structure of a COOrdinate list structure allows partial evaluator to use more aggressive optimizations such as \textcolor{blue}{vectorization} or easier loop unfolding.

For graph algorithms in a matrix form (matrix multiplication and Kronecker product), we may \textcolor{red}{observe} that partially evaluated algorithms' code underperforms code of the same algorithms implemented with SuiteSparse GraphBLAS \textcolor{red}{in} 10 times in average. It could be considered as good result, since non-partially evaluated code loses 100 times in the half of cases.

To sum up, for the selected string algorithms partially evaluated code outperforms their industrial implementations by execution time in high degree; for the selected graph algorithms in matrix form partially evaluated code lags behind their state-of-art implementation by a factor of 10 (which is a good result).


\subsection{How does partial evaluator influences algorithms' code size?}

\colorbox{red}{blah-blah-blah}

\section{Threats to validity}

\subsection{Subject selection bias}
In our research we use only AnyDSL framework for the experiments. Another partial evaluation tools may give slightly different results due more or less aggressive optimizations or different evaluation techniques.

\subsection{Used datasets}
Despite trying to run experimental code on both versatile and special datasets, we admit that partially evaluated code could give slightly different measures on some other special degenerate matrix sets.

\section{Related work}

Partial evaluation of linear algebra (matrix algorithms) was studied before in several papers.

Firstly, colleagues measured \cite{tyurin2020optimizing} that partial evaluation of matrix convolution and pattern matching algorithms using AnyDSL framework and CUDA reduces execution times significantly on the most datasets.

Secondly, some research was performed on Viterbi algorithm partial evaluation.  \textcolor{red}{There should be the description of Ivan's work. I do not understand the topic enough at the moment}

Also, AnyDSL team performed research \cite{perard2019rodent} on application of partial evaluation for ray tracing purposes in their library named Rodent. It was measured that partial evaluation  makes an improvement in execution time of around $25\%$ on selected datasets.


\bibliographystyle{ieeetran}
\bibliography{syrcose}

\end{document}
